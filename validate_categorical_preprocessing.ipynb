{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils.dataset import baseline_preprocessing, fetch_openml_dataset_by_id, nan_feat_preprocessing\n",
    "from models.gradient_boosting import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "METHOD_CHOICES = [\"baseline\", \"nan_feat\"]\n",
    "\n",
    "\n",
    "def train_by_baseline(\n",
    "    openml_id: int,\n",
    "    seed: Optional[int] = None,\n",
    "    method: Literal[\"baseline\", \"nan_feat\"] = \"baseline\"\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    if method not in METHOD_CHOICES:\n",
    "        raise ValueError(f\"method must be in {METHOD_CHOICES}, but got {method}\")\n",
    "    \n",
    "    preproc = baseline_preprocessing if method == \"baseline\" else nan_feat_preprocessing\n",
    "\n",
    "    # id: {2, 41138} --> {anneal, APSFailure}\n",
    "    X_train, X_test, y_train, y_test, weight_train, weight_test = preproc(\n",
    "        *fetch_openml_dataset_by_id(openml_id, seed=seed)\n",
    "    )\n",
    "    print(X_train.shape)\n",
    "    gb = GradientBoostingClassifier(seed=seed)\n",
    "    gb.fit(X_train, y_train, sample_weight=weight_train)\n",
    "    preds = gb.predict(X_test)\n",
    "    return preds, y_test, weight_test\n",
    "\n",
    "\n",
    "def accuracy(preds: np.ndarray, labels: np.ndarray, weights: Optional[np.ndarray] = None) -> float:\n",
    "    weights = weights if weights is not None else np.ones_like(labels) / labels.size\n",
    "    return (preds == labels) @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(673, 83)\n",
      "0.9576184300645093 0.9244444444444446\n",
      "(673, 136)\n",
      "0.9576184300645094 0.9244444444444446\n",
      "(57000, 170)\n",
      "0.9381362532426982 0.9590526315789469\n",
      "(57000, 509)\n",
      "0.9381362532426982 0.9590526315789469\n"
     ]
    }
   ],
   "source": [
    "for data_id in [2, 41138]:\n",
    "    preds, labels, weights = train_by_baseline(data_id, seed=0, method=\"baseline\")\n",
    "    print(accuracy(preds, labels, weights), accuracy(preds, labels))\n",
    "\n",
    "    preds, labels, weights = train_by_baseline(data_id, seed=0, method=\"nan_feat\")\n",
    "    print(accuracy(preds, labels, weights), accuracy(preds, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
